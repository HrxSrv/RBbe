# RecruitBot - Smart Candidate Hiring Platform

Platform for smart candidate hiring with AI-powered resume analysis and automated call scheduling.

## üéØ Project Overview

**‚ö†Ô∏è MAJOR ARCHITECTURE CHANGE: Internal HR Tool Only**

**RecruitBot** has been transformed into an **internal HR tool** that combines:
- **Company Management** - Customer onboarding and team management
- **Internal Job Management** - HR-only access to job postings with full question visibility
- **HR Resume Upload System** - HR uploads candidate resumes with optional candidate info
- **Resume Analysis** - VLM-powered resume evaluation and candidate matching
- **Upload Tracking & Audit** - Complete audit trail of who uploaded each candidate
- **Automated Calling** - VAPI integration for scheduled candidate interviews
- **Analytics Dashboard** - Performance metrics and hiring insights

## üèóÔ∏è Architecture

- **FastAPI** - Modern, fast web framework with automatic API documentation
- **MongoDB Atlas** - Cloud NoSQL database with Beanie ODM
- **Beanie ODM** - Async MongoDB ODM with Pydantic v2 integration
- **Google OAuth 2.0** - Authentication system with JWT tokens
- **VLM Integration** - Resume analysis and candidate scoring
- **VAPI** - Voice AI for automated candidate calls
- **Pydantic v2** - Type-safe data validation and serialization

## üìä Current Development Status

### ‚úÖ **Day 1 - Foundation, Authentication & RBAC** (100% COMPLETED)

**Database Models & Schemas:**
- ‚úÖ Customer model (company details, subscription plans, timestamps)
- ‚úÖ User model (role-based access: super_admin, company_admin, recruiter, viewer)
- ‚úÖ Job model (job postings with requirements, salary, location)
- ‚úÖ Candidate model (resume analysis, application tracking)
- ‚úÖ Call model (VAPI call scheduling and results)
- ‚úÖ All models with proper timestamp fields and Beanie ODM integration

**Infrastructure:**
- ‚úÖ Beanie ODM integration for clean database operations
- ‚úÖ MongoDB Atlas connection with proper error handling
- ‚úÖ Google OAuth authentication with JWT tokens
- ‚úÖ Environment-based configuration management
- ‚úÖ Comprehensive logging with Loguru
- ‚úÖ CORS middleware and request logging

**Authentication & Authorization:**
- ‚úÖ Google OAuth authentication flow
- ‚úÖ JWT token validation and refresh
- ‚úÖ Complete RBAC system with 27 granular permissions
- ‚úÖ 4-tier role hierarchy (Super Admin ‚Üí Company Admin ‚Üí Recruiter ‚Üí Viewer)
- ‚úÖ Permission decorators: `@require_permission()`, `@require_role()`, `@require_admin()`
- ‚úÖ Role-based endpoint protection

**Customer Management:**
- ‚úÖ Public company registration endpoint (`/customers/register`)
- ‚úÖ Customer CRUD operations with access control
- ‚úÖ Company data validation and duplicate prevention
- ‚úÖ Subscription plan management (Free ‚Üí Professional ‚Üí Enterprise)

**User Management & Invitations:**
- ‚úÖ Complete user invitation system (`/invitations/invite`, `/invitations/accept`)
- ‚úÖ 7-day expiration on invitations with status tracking
- ‚úÖ Role assignment during invitation (Recruiter/Viewer)
- ‚úÖ Company-scoped user operations and listing
- ‚úÖ User deactivation (admin-only)

**API Endpoints:**
- ‚úÖ Health check and database testing
- ‚úÖ Comprehensive Day 1 feature testing endpoint
- ‚úÖ Sample data creation for all models
- ‚úÖ Protected user management endpoints

### ‚úÖ **Day 2: Enhanced Job Management + Q&A System** (100% COMPLETED)

**Core Job CRUD Operations:**
- ‚úÖ Job model with comprehensive fields (title, description, requirements, salary, location)
- ‚úÖ Job creation endpoint with RBAC protection (`@require_permission(Permission.CREATE_JOB)`)
- ‚úÖ Job update/edit functionality for recruiters and admins
- ‚úÖ Job deletion and status management (draft ‚Üí active ‚Üí paused ‚Üí closed)
- ‚úÖ Job publish/unpublish workflow with status transitions

**Enhanced Job Features:**
- ‚úÖ Job search with multiple filters (location, job type, status, experience level)
- ‚úÖ Pagination and sorting for job listings (skip/limit with validation)
- ‚úÖ Advanced location filtering with regex-based search
- ‚úÖ Job type and status enum validation
- ‚úÖ Company data isolation (users only see their company's jobs)

**üÜï Job Questions System:**
- ‚úÖ Multi-question setup with ideal answers for each job
- ‚úÖ Question weighting system (importance scoring)
- ‚úÖ Questions included in all job CRUD operations
- ‚úÖ Security: Ideal answers hidden in public job listings
- ‚úÖ Integration ready for VLM analysis and VAPI calls

**üÜï Candidate Q&A Framework:**
- ‚úÖ Complete QA data structure for call interviews
- ‚úÖ Individual question-answer scoring system
- ‚úÖ Call summary and analysis tracking
- ‚úÖ Interview duration and performance metrics
- ‚úÖ Integration points for VLM answer analysis

**Job Analytics & Tracking:**
- ‚úÖ Job view count tracking (auto-increment on job access)
- ‚úÖ Application count per job tracking
- ‚úÖ Job analytics summary endpoint (`/jobs/analytics/summary`)
- ‚úÖ Performance metrics (view-to-application ratios)
- ‚úÖ Company-level job statistics and insights

**üö® UPDATED: Internal Job Management Workflow:**
- ‚ö†Ô∏è **REMOVED**: `GET /jobs/public/list` - No longer available ‚ùå
- ‚ö†Ô∏è **REMOVED**: `GET /jobs/public/{id}` - No longer available ‚ùå
- ‚úÖ **NEW**: Internal job listing endpoints (`/jobs/dev/list` - auth required)
- ‚úÖ **NEW**: Internal job detail view endpoint (`/jobs/dev/{id}` - auth required)
- ‚úÖ **Enhanced**: Full access to interview questions including ideal answers for internal users
- ‚úÖ Advanced filtering for internal job management (location, type, remote)
- ‚úÖ HR-focused browsing with authentication and customer isolation

**Integration Preparations:**
- ‚úÖ Job-to-candidate matching algorithm foundation (TODO comments ready)
- ‚úÖ VLM integration points prepared for Q&A analysis
- ‚úÖ VAPI call scheduling integration points with Q&A questions
- ‚úÖ Answer scoring and analysis framework complete

**jobs** - Job postings with interview questions
```javascript
{
  "_id": ObjectId,
  "customer_id": Link[Customer],
  "created_by": Link[User],
  "title": "Senior Python Developer",
  "description": "Job description...",
  "requirements": ["Python", "FastAPI", "MongoDB"],
  "location": "San Francisco, CA",
  
  // Enhanced: Interview Questions
  "questions": [
    {
      "question": "What is your experience with FastAPI?",
      "ideal_answer": "I have 3+ years experience building REST APIs with FastAPI, including authentication, database integration, and async operations.",
      "weight": 1.5
    },
    {
      "question": "How do you handle database optimization?",
      "ideal_answer": "I use indexing strategies, query optimization, connection pooling, and caching mechanisms like Redis for performance.",
      "weight": 1.0
    }
  ],
  
  "salary_range": {
    "min_salary": 120000,
    "max_salary": 160000,
    "currency": "USD"
  },
  "job_type": "full_time", // full_time, part_time, contract, internship
  "status": "active", // draft, active, paused, closed
  "department": "Engineering",
  "experience_level": "senior",
  "remote_allowed": true,
  "application_deadline": datetime,
  "view_count": 0,
  "application_count": 0,
  "created_at": datetime,
  "updated_at": datetime
}
```

**candidates** - Candidate profiles with Q&A data
```javascript
{
  "_id": ObjectId,
  "personal_info": {
    "name": "Alice Johnson",
    "email": "alice@example.com",
    "phone": "+1-555-0123",
    "location": "New York, NY"
  },
  "resume_analysis": {
    "skills": ["Python", "FastAPI", "React"],
    "experience_years": 6,
    "education": "BS Computer Science",
    "previous_roles": ["Senior Engineer"],
    "matching_score": 87.5,
    "analysis_summary": "Strong technical background...",
    "resume_file_path": "/uploads/resumes/alice.pdf"
  },
  "applications": [
    {
      "job_id": "job_objectid",
      "application_date": datetime,
      "status": "applied", // applied, screening, interview, rejected, hired
      "matching_score": 87.5,
      "notes": "Strong candidate",
      
      // Enhanced: Call Q&A Data
      "call_qa": {
        "call_id": "call_456",
        "call_date": datetime,
        "questions_answers": [
          {
            "question": "What is your experience with FastAPI?",
            "answer": "I have been working with FastAPI for about 4 years, primarily building microservices...",
            "ideal_answer": "I have 3+ years experience building REST APIs with FastAPI...",
            "score": 92.5,
            "analysis": "Excellent answer that exceeds the ideal response with specific technical details."
          }
        ],
        "overall_score": 88.7,
        "interview_summary": "Candidate demonstrates strong technical skills with excellent FastAPI knowledge.",
        "call_duration_minutes": 35
      }
    }
  ],
  "total_applications": 1,
  "status": "active", // active, hired, inactive
  "created_at": datetime,
  "updated_at": datetime
}
```

**calls** - VAPI call scheduling and tracking
```javascript
{
  "_id": ObjectId,
  "candidate_id": Link[Candidate],
  "job_id": Link[Job],
  "customer_id": Link[Customer],
  "scheduled_time": datetime,
  "call_type": "screening", // screening, interview, follow_up
  "status": "scheduled", // scheduled, in_progress, completed, cancelled, no_show, failed
  "vapi_call_id": "vapi_call_123",
  "vapi_assistant_id": "assistant_456",
  "call_duration": 1800, // seconds
  "call_summary": "Positive screening call",
  "call_transcript": "Full call transcript...",
  "call_recording_url": "https://recordings.vapi.ai/...",
  "candidate_score": 78.5,
  "interviewer_notes": "Strong technical skills",
  "next_steps": "Schedule technical interview",
  "scheduled_by": "user_id",
  "rescheduled_count": 0,
  "created_at": datetime,
  "updated_at": datetime
}
```

### ‚úÖ **Day 3: Resume Processing & VLM Integration** (100% COMPLETED)

**Complete Resume-to-VLM Workflow with Public Job Application System**

#### **‚úÖ Core Infrastructure Implementation**:
- ‚úÖ **File Upload Infrastructure** - Secure multipart upload with validation
- ‚úÖ **Text Extraction Service** - Multi-format processing (PDF, DOC, DOCX) 
- ‚úÖ **Gemini VLM Integration** - Intelligent resume analysis with job context
- ‚úÖ **Public Job Application System** - Seamless candidate experience without authentication
- ‚úÖ **Internal Candidate Management** - Comprehensive company tools with RBAC

#### **‚úÖ Step 1: File Upload System** - COMPLETED
- ‚úÖ Secure file upload with MIME type validation (PDF, DOC, DOCX)
- ‚úÖ File size limits and security checks (10MB max)
- ‚úÖ Organized storage structure (`uploads/resumes/{customer_id}/{candidate_id}/`)
- ‚úÖ Complete file lifecycle management (upload, metadata, cleanup)
- ‚úÖ Public and internal endpoint architecture
- ‚úÖ Automatic customer ID association from job context

#### **‚úÖ Step 2: Text Extraction Service** - COMPLETED  
- ‚úÖ Multi-format text extraction with quality assessment
- ‚úÖ Dual PDF processing strategy (PyPDF2 + pdfplumber)
- ‚úÖ DOC/DOCX processing with python-docx
- ‚úÖ Confidence scoring and VLM routing recommendations (0.0-1.0)
- ‚úÖ Batch processing capabilities with error handling
- ‚úÖ Intelligent preprocessing and normalization

#### **‚úÖ Step 3: Gemini VLM Integration Service** - COMPLETED
- ‚úÖ **Dual-model strategy**: gemini-1.5-flash (text) + gemini-1.5-pro (vision)
- ‚úÖ **Intelligent routing**: Quality-based model selection (<0.7 confidence ‚Üí vision)
- ‚úÖ **Complete resume analysis**: Skills extraction, experience assessment, education parsing
- ‚úÖ **Job context integration**: Job-specific matching and compatibility scoring
- ‚úÖ **Q&A readiness assessment**: Interview preparation scoring for Day 2 questions
- ‚úÖ **Batch processing**: Concurrent analysis with rate limiting (max 3)
- ‚úÖ **Structured output**: Consistent JSON parsing with comprehensive error handling
- ‚úÖ **Cost optimization**: Smart routing for efficient API usage

#### **üö® UPDATED: Step 4: HR Resume Upload System** - CONVERTED TO INTERNAL
- ‚ö†Ô∏è **REMOVED**: `/candidates/public/apply-to-job/{job_id}` - No longer available ‚ùå
- ‚ö†Ô∏è **REMOVED**: `/candidates/public/application-status/{email}` - No longer available ‚ùå
- ‚úÖ **NEW HR Endpoints**: `/candidates/upload-resume-for-job/{job_id}`, `/candidates/upload-resume`, `/candidates/{id}/associate-job/{job_id}`
- ‚úÖ **Internal Endpoints**: `/candidates/`, `/candidates/{id}`, `/candidates/analyze-resume/{id}`, etc.
- ‚úÖ **Data Flow**: HR Login ‚Üí Upload Resume ‚Üí Customer ID ‚Üí File Storage ‚Üí Candidate Profile
- ‚úÖ **Security**: Universal authentication requirement with proper RBAC integration
- ‚úÖ **Upload Tracking**: Complete audit trail with `uploaded_by` and `upload_source` fields
- ‚úÖ **Optional Fields**: VLM-ready system with "To be extracted by VLM" placeholders

#### **‚úÖ Integration Architecture**:
- ‚úÖ **Public Application Flow**: Job browsing ‚Üí Resume upload ‚Üí VLM analysis ‚Üí Profile creation
- ‚úÖ **Internal Management Flow**: Company login ‚Üí Candidate review ‚Üí Status updates ‚Üí Analysis triggers
- ‚úÖ **Day 2 Integration**: Job questions system fully integrated for Q&A assessment
- ‚úÖ **Day 4 Ready**: Complete candidate-to-company workflow prepared

**API Endpoints Implemented:**
```bash
# PUBLIC (No Authentication) - For Job Seekers
POST   /api/v1/candidates/public/apply-to-job/{job_id}    # Apply to job with resume
GET    /api/v1/candidates/public/application-status/{email} # Check application status

# INTERNAL (Authentication Required) - For Companies  
GET    /api/v1/candidates/                                # List company candidates
GET    /api/v1/candidates/{id}                            # Get candidate details
PUT    /api/v1/candidates/{id}/status                     # Update application status
POST   /api/v1/candidates/analyze-resume/{id}             # Trigger VLM analysis
POST   /api/v1/candidates/qa-assessment/{id}              # Q&A readiness evaluation
POST   /api/v1/candidates/batch-analyze                   # Bulk candidate processing
GET    /api/v1/candidates/files/{id}/metadata             # File metadata retrieval
DELETE /api/v1/candidates/files/{id}                      # File deletion with cleanup

# Testing & Validation
GET    /api/v1/test-day3-step1-file-upload                # File upload validation
GET    /api/v1/test-day3-step2-text-extraction            # Text extraction validation  
GET    /api/v1/test-day3-step3-gemini-integration         # VLM integration validation
POST   /api/v1/test-day3-complete-fixed                   # Complete architecture test
```

**Technical Implementation Highlights:**
- **Dual endpoint architecture**: Seamless separation of public and internal workflows
- **Multi-model VLM strategy** for cost-effective processing
- **Smart routing logic** based on text extraction confidence (<0.7 triggers vision)
- **Enhanced Q&A integration** with Day 2 job questions system
- **Robust error handling** with graceful degradation and detailed logging
- **RBAC security** throughout all internal operations
- **Customer data isolation** with automatic job-to-company association
- **Optimized user experience**: Frictionless candidate job applications

**Day 3 Status**: COMPLETE AND PRODUCTION READY

## üöÄ Quick Start

### Prerequisites
- Python 3.12+
- MongoDB Atlas account
- Google OAuth credentials
- UV package manager

### Installation

```bash
# Clone repository
git clone <repository-url>
cd RecruitBotv2

# Install dependencies
uv sync

# Copy environment configuration
cp envexample.txt newenv.txt
# Edit newenv.txt with your configuration
```

### Environment Setup

Update `newenv.txt` with your credentials:

```bash
# Database
MONGODB_URL=mongodb+srv://username:password@cluster.mongodb.net/
MONGODB_DATABASE=recruitbot_dev

# Google OAuth
GOOGLE_CLIENT_ID=your-client-id.apps.googleusercontent.com
GOOGLE_CLIENT_SECRET=your-client-secret

# JWT Security
JWT_SECRET_KEY=your-32-character-secret-key
```

### Run Development Server

```bash
# Start the server
uv run run.py dev

# Verify health
curl http://localhost:8000/api/v1/health
```

## üß™ Testing the System

### Test Day 1 Completion
```bash
curl http://localhost:8000/api/v1/test-day1-features
```

This comprehensive test validates:
- ‚úÖ RBAC system with 27 permissions across 4 roles
- ‚úÖ Permission hierarchy and role validation
- ‚úÖ Database models and relationships
- ‚úÖ Router integration and endpoint availability

### Test Day 2 Enhanced Features
```bash
curl -X POST http://localhost:8000/api/v1/test-day2-enhanced-features
```

This comprehensive test validates:
- ‚úÖ Job questions schema validation and structure
- ‚úÖ Candidate QA framework validation
- ‚úÖ Integration readiness for Day 3 (VLM) and Day 4-5 (VAPI)
- ‚úÖ Complete schema hierarchy for Q&A data

### Test Day 3 Implementation
```bash
# Test complete Day 3 implementation
curl -X POST http://localhost:8000/api/v1/test-day3-complete-fixed

# Test individual Day 3 components
curl -X GET http://localhost:8000/api/v1/test-day3-step1-file-upload
curl -X GET http://localhost:8000/api/v1/test-day3-step2-text-extraction
curl -X GET http://localhost:8000/api/v1/test-day3-step3-gemini-integration
```

### üÜï Test Internal Tool Architecture
```bash
# Test the complete architectural transformation
curl -X GET http://localhost:8000/api/v1/test-internal-tool-architecture
```

This comprehensive test validates:
- ‚úÖ **Architecture transformation**: Conversion from public platform to internal HR tool
- ‚úÖ **Endpoint changes**: Public endpoints removed, internal dev endpoints added
- ‚úÖ **Authentication requirements**: All operations require valid JWT tokens
- ‚úÖ **Upload system**: HR resume upload with optional field handling
- ‚úÖ **Tracking fields**: Upload audit trail with `uploaded_by` and `upload_source`
- ‚úÖ **Customer isolation**: Proper data filtering and RBAC integration

### üö® UPDATED: Test HR Resume Upload System
```bash
# ‚ö†Ô∏è UPDATED: HR upload system (auth required)
curl -X POST -H "Authorization: Bearer $ACCESS_TOKEN" http://localhost:8000/api/v1/candidates/upload-resume-for-job/{job_id} \
  -F "resume=@resume.pdf" \
  -F "candidate_name=John Doe" \
  -F "candidate_email=john@example.com" \
  -F "candidate_phone=+1-555-0123" \
  -F "candidate_location=New York, NY"

# Upload to general candidate pool
curl -X POST -H "Authorization: Bearer $ACCESS_TOKEN" http://localhost:8000/api/v1/candidates/upload-resume \
  -F "resume=@resume.pdf" \
  -F "candidate_name=Jane Smith"

# Associate existing candidate with job
curl -X POST -H "Authorization: Bearer $ACCESS_TOKEN" http://localhost:8000/api/v1/candidates/{candidate_id}/associate-job/{job_id}
```

This comprehensive test validates:
- ‚úÖ **HR resume upload system**: Authenticated HR tool for candidate management
- ‚úÖ File upload infrastructure with security validation
- ‚úÖ Multi-format text extraction (PDF, DOC, DOCX) with quality assessment
- ‚úÖ Gemini VLM service integration with dual-model strategy
- ‚úÖ Job context-aware resume analysis and Q&A readiness assessment
- ‚úÖ Internal authentication-only architecture with proper RBAC
- ‚úÖ Upload tracking and audit trail with `uploaded_by` field
- ‚úÖ Optional field system with VLM-ready placeholders
- ‚úÖ Customer data isolation and proper job association
- ‚úÖ Complete internal HR workflow for production use

### Test Job Creation with Questions
```bash
curl -X POST http://localhost:8000/api/v1/jobs/ \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "title": "Senior Python Developer with Q&A",
    "description": "Looking for experienced Python developer - Enhanced with interview questions",
    "requirements": ["Python", "FastAPI", "MongoDB"],
    "location": "San Francisco, CA",
    "job_type": "full_time",
    "questions": [
      {
        "question": "What is your experience with FastAPI?",
        "ideal_answer": "I have 3+ years experience building REST APIs with FastAPI, including authentication, database integration, and async operations.",
        "weight": 1.5
      },
      {
        "question": "How do you handle database optimization?",
        "ideal_answer": "I use indexing strategies, query optimization, connection pooling, and caching mechanisms like Redis for performance.",
        "weight": 1.0
      }
    ]
  }'
```

### Test Customer Registration
```bash
curl -X POST http://localhost:8000/api/v1/customers/register \
  -H "Content-Type: application/json" \
  -d '{
    "company_name": "NewTech Corp",
    "email": "admin@newtech.com",
    "website": "https://newtech.com",
    "industry": "SaaS",
    "company_size": "10-50"
  }'
```

### Test Database Connection
```bash
curl http://localhost:8000/api/v1/test-db
```

### Create Sample Data
```bash
curl -X POST http://localhost:8000/api/v1/create-sample-data
```

This creates a complete data set:
- **1 Customer:** TechCorp Solutions (Professional plan)
- **2 Users:** John Admin (company_admin) + Jane Recruiter (recruiter)
- **1 Job:** Senior Python Developer ($120K-$160K, Remote allowed)
- **1 Candidate:** Alice Johnson (87.5% match, 6 years experience)
- **1 Call:** Scheduled screening call (2 days from creation)

### Test RBAC System
```bash
# This endpoint shows permission counts per role:
# Super Admin: 27 permissions
# Company Admin: 23 permissions  
# Recruiter: 14 permissions
# Viewer: 6 permissions
curl http://localhost:8000/api/v1/test-day1-features | jq '.rbac_system'
```

### Verify in MongoDB Atlas
Check your database collections:
- `customers` - Company data with subscription plans
- `users` - Team members with role-based access
- `jobs` - Job postings with requirements and salary ranges
- `candidates` - Candidate profiles with resume analysis
- `calls` - Scheduled calls with VAPI integration points

## üìö API Documentation

### Current Endpoints

**Authentication:**
- `POST /api/v1/auth/google` - Google OAuth login
- `GET /api/v1/auth/validate` - Validate JWT token
- `POST /api/v1/auth/logout` - User logout

**Customer Management:**
- `POST /api/v1/customers/register` - Public company registration
- `GET /api/v1/customers/` - List customers (admin only)
- `GET /api/v1/customers/{id}` - Get customer details
- `PUT /api/v1/customers/{id}` - Update customer details
- `DELETE /api/v1/customers/{id}` - Deactivate customer (super admin)

**User Management:**
- `GET /api/v1/users/me` - Get current user profile
- `GET /api/v1/users/` - List company users (role-filtered)
- `GET /api/v1/users/{id}` - Get user details
- `PUT /api/v1/users/{id}/deactivate` - Deactivate user (admin)

**Invitations:**
- `POST /api/v1/invitations/invite` - Invite team member (admin/company_admin)
- `POST /api/v1/invitations/accept/{id}` - Accept invitation (public)

**Job Management:**
- `POST /api/v1/jobs/` - Create job posting (recruiter+)
- `GET /api/v1/jobs/` - List jobs with filtering and pagination (recruiter+)
- `GET /api/v1/jobs/{id}` - Get job details with view tracking (recruiter+)
- `PUT /api/v1/jobs/{id}` - Update job details (recruiter+)
- `DELETE /api/v1/jobs/{id}` - Archive job (soft delete) (recruiter+)
- `POST /api/v1/jobs/{id}/publish` - Publish job (draft ‚Üí active) (recruiter+)
- `GET /api/v1/jobs/analytics/summary` - Job analytics and metrics (recruiter+)

**Public Job Endpoints (No Authentication):**
- `GET /api/v1/jobs/public/list` - Browse active jobs (public)
- `GET /api/v1/jobs/public/{id}` - View job details (public)

**System & Testing:**
- `GET /api/v1/health` - Health check
- `GET /api/v1/test-db` - Database connection test
- `GET /api/v1/test-day1-features` - Comprehensive Day 1 functionality test
- `GET /api/v1/test-day2-features` - Comprehensive Day 2 job management test
- `POST /api/v1/test-day2-enhanced-features` - Enhanced Day 2 Q&A system test
- `POST /api/v1/create-sample-data` - Create test data

**Interactive Documentation:**
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

## üîß Development Workflow

### Project Structure
```
app/
‚îú‚îÄ‚îÄ main.py                 # Application entry point
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ settings.py         # Environment configuration
‚îÇ   ‚îî‚îÄ‚îÄ database.py         # MongoDB + Beanie setup
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ auth.py            # JWT authentication
‚îÇ   ‚îú‚îÄ‚îÄ middleware.py      # Request/response middleware
‚îÇ   ‚îî‚îÄ‚îÄ logging_config.py  # Logging setup
‚îú‚îÄ‚îÄ api/v1/
‚îÇ   ‚îú‚îÄ‚îÄ routes.py          # Main API router
‚îÇ   ‚îî‚îÄ‚îÄ endpoints/
‚îÇ       ‚îú‚îÄ‚îÄ auth.py        # Authentication endpoints
‚îÇ       ‚îî‚îÄ‚îÄ users.py       # User management
‚îú‚îÄ‚îÄ models/                 # Beanie document models
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py        # Model imports & rebuilding
‚îÇ   ‚îú‚îÄ‚îÄ customer.py        # Customer/Company model
‚îÇ   ‚îú‚îÄ‚îÄ user.py           # User model with roles
‚îÇ   ‚îú‚îÄ‚îÄ job.py            # Job posting model
‚îÇ   ‚îú‚îÄ‚îÄ candidate.py      # Candidate profile model
‚îÇ   ‚îî‚îÄ‚îÄ call.py           # Call scheduling model
‚îú‚îÄ‚îÄ schemas/               # Pydantic request/response schemas
‚îÇ   ‚îî‚îÄ‚îÄ schemas.py
‚îî‚îÄ‚îÄ services/              # Business logic services
    ‚îî‚îÄ‚îÄ google_oauth.py
```

### Adding New Features

1. **Define Model** in `app/models/`
2. **Add to __init__.py** imports and model rebuilding
3. **Create Schemas** in `app/schemas/`
4. **Implement Endpoints** in `app/api/v1/endpoints/`
5. **Register Routes** in `app/api/v1/routes.py`

### Database Operations with Beanie

```python
# Create
customer = Customer(company_name="New Company", email="test@company.com")
await customer.save()

# Find
customer = await Customer.find_one(Customer.email == "test@company.com")
customers = await Customer.find(Customer.is_active == True).to_list()

# Update
await customer.set({Customer.company_name: "Updated Name"})

# Delete
await customer.delete()
```

## üö¢ Deployment

Ready for deployment on:
- **Railway** - Automatic deployment from Git
- **Docker** - Containerized deployment
- **Any cloud provider** supporting Python apps

## üîí Security Features

- JWT token authentication
- Role-based access control (in progress)
- Google OAuth integration
- Environment-based secrets management
- CORS protection
- Input validation with Pydantic

## üéØ Next Steps

1. ‚úÖ **Day 1 COMPLETED** - RBAC middleware and user invitation system implemented
2. ‚úÖ **Day 2 COMPLETED** - Job management system with Q&A framework
3. ‚úÖ **Day 3 COMPLETED** - Resume processing and Gemini VLM integration
4. **Day 4** - Enhanced candidate management with VLM workflow
5. **Day 5** - VAPI integration for automated voice interviews
6. **Day 6** - Admin dashboard and production deployment

---

**Current Status:** Day 3 Complete ‚úÖ (Resume Processing & VLM Integration - Public job application system + Internal candidate management with complete VLM workflow) 